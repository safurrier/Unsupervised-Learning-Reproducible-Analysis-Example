{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ruamel.yaml as yaml\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "# ## Change to Root\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "NO_CONFIG_ERR_MSG = \"\"\"No config file found. Root directory is determined by presence of \"config.yaml\" file.\"\"\"        \n",
    "\n",
    "original_wd = os.getcwd()\n",
    "\n",
    "# Number of times to move back in directory\n",
    "num_retries = 10\n",
    "for x in range(0, num_retries):\n",
    "    # try to load config file    \n",
    "    try:\n",
    "        with open(\"config.yaml\", 'r') as stream:\n",
    "            cfg = yaml.safe_load(stream)\n",
    "    # If not found move back one directory level\n",
    "    except FileNotFoundError:\n",
    "        os.chdir('../')\n",
    "        # If reached the max number of directory levels change to original wd and print error msg\n",
    "        if x+1 == num_retries:\n",
    "            os.chdir(original_wd)\n",
    "            print(NO_CONFIG_ERR_MSG)\n",
    "            \n",
    "# Add directory to PATH\n",
    "path = os.getcwd()\n",
    "\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean results so that similar outputs are organized by UL technique, dataset and metric/result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First clean based on one set and then expand to all others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Cleaning the Clustering Quality Metrics (SSE (minimize) for K Means, log likelihood (maximize) for GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clustering_Algorithm</th>\n",
       "      <th>N_Clusters</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>2</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>25919.169412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>5</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>23805.080932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>10</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>21680.907243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>15</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>20389.563032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>20</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>19498.187803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>25</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>18810.762444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>30</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>18196.739312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>35</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>17761.460021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>40</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>17291.711202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>2</td>\n",
       "      <td>Cars</td>\n",
       "      <td>SSE</td>\n",
       "      <td>20441.927175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>5</td>\n",
       "      <td>Cars</td>\n",
       "      <td>SSE</td>\n",
       "      <td>16487.993517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>10</td>\n",
       "      <td>Cars</td>\n",
       "      <td>SSE</td>\n",
       "      <td>14458.596181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>15</td>\n",
       "      <td>Cars</td>\n",
       "      <td>SSE</td>\n",
       "      <td>12721.524125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>20</td>\n",
       "      <td>Cars</td>\n",
       "      <td>SSE</td>\n",
       "      <td>11919.971623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>25</td>\n",
       "      <td>Cars</td>\n",
       "      <td>SSE</td>\n",
       "      <td>11240.393237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>30</td>\n",
       "      <td>Cars</td>\n",
       "      <td>SSE</td>\n",
       "      <td>10801.409464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>35</td>\n",
       "      <td>Cars</td>\n",
       "      <td>SSE</td>\n",
       "      <td>10528.748074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>40</td>\n",
       "      <td>Cars</td>\n",
       "      <td>SSE</td>\n",
       "      <td>10001.674627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EM</td>\n",
       "      <td>2</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-21.243584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>EM</td>\n",
       "      <td>5</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-20.922156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>EM</td>\n",
       "      <td>10</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-20.593894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>EM</td>\n",
       "      <td>15</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-20.232891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>EM</td>\n",
       "      <td>20</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-19.926389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EM</td>\n",
       "      <td>25</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-19.537038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EM</td>\n",
       "      <td>30</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-19.232486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>EM</td>\n",
       "      <td>35</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-19.041576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>EM</td>\n",
       "      <td>40</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-18.793429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EM</td>\n",
       "      <td>2</td>\n",
       "      <td>Cars</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>-3.918560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EM</td>\n",
       "      <td>5</td>\n",
       "      <td>Cars</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>11.927310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EM</td>\n",
       "      <td>10</td>\n",
       "      <td>Cars</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>20.843802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>EM</td>\n",
       "      <td>15</td>\n",
       "      <td>Cars</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>27.733159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>EM</td>\n",
       "      <td>20</td>\n",
       "      <td>Cars</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>31.476573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>EM</td>\n",
       "      <td>25</td>\n",
       "      <td>Cars</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>31.696820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>EM</td>\n",
       "      <td>30</td>\n",
       "      <td>Cars</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>35.064243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>EM</td>\n",
       "      <td>35</td>\n",
       "      <td>Cars</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>35.750997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EM</td>\n",
       "      <td>40</td>\n",
       "      <td>Cars</td>\n",
       "      <td>log-likelihood</td>\n",
       "      <td>37.775342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clustering_Algorithm  N_Clusters  Dataset          Metric         Value\n",
       "0               K_Means           2  Madelon             SSE  25919.169412\n",
       "1               K_Means           5  Madelon             SSE  23805.080932\n",
       "2               K_Means          10  Madelon             SSE  21680.907243\n",
       "3               K_Means          15  Madelon             SSE  20389.563032\n",
       "4               K_Means          20  Madelon             SSE  19498.187803\n",
       "5               K_Means          25  Madelon             SSE  18810.762444\n",
       "6               K_Means          30  Madelon             SSE  18196.739312\n",
       "7               K_Means          35  Madelon             SSE  17761.460021\n",
       "8               K_Means          40  Madelon             SSE  17291.711202\n",
       "9               K_Means           2     Cars             SSE  20441.927175\n",
       "10              K_Means           5     Cars             SSE  16487.993517\n",
       "11              K_Means          10     Cars             SSE  14458.596181\n",
       "12              K_Means          15     Cars             SSE  12721.524125\n",
       "13              K_Means          20     Cars             SSE  11919.971623\n",
       "14              K_Means          25     Cars             SSE  11240.393237\n",
       "15              K_Means          30     Cars             SSE  10801.409464\n",
       "16              K_Means          35     Cars             SSE  10528.748074\n",
       "17              K_Means          40     Cars             SSE  10001.674627\n",
       "18                   EM           2  Madelon  log-likelihood    -21.243584\n",
       "19                   EM           5  Madelon  log-likelihood    -20.922156\n",
       "20                   EM          10  Madelon  log-likelihood    -20.593894\n",
       "21                   EM          15  Madelon  log-likelihood    -20.232891\n",
       "22                   EM          20  Madelon  log-likelihood    -19.926389\n",
       "23                   EM          25  Madelon  log-likelihood    -19.537038\n",
       "24                   EM          30  Madelon  log-likelihood    -19.232486\n",
       "25                   EM          35  Madelon  log-likelihood    -19.041576\n",
       "26                   EM          40  Madelon  log-likelihood    -18.793429\n",
       "27                   EM           2     Cars  log-likelihood     -3.918560\n",
       "28                   EM           5     Cars  log-likelihood     11.927310\n",
       "29                   EM          10     Cars  log-likelihood     20.843802\n",
       "30                   EM          15     Cars  log-likelihood     27.733159\n",
       "31                   EM          20     Cars  log-likelihood     31.476573\n",
       "32                   EM          25     Cars  log-likelihood     31.696820\n",
       "33                   EM          30     Cars  log-likelihood     35.064243\n",
       "34                   EM          35     Cars  log-likelihood     35.750997\n",
       "35                   EM          40     Cars  log-likelihood     37.775342"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg = 'BASE'\n",
    "sse_base = pd.read_csv(f'{alg}/SSE.csv')\n",
    "# Adjust column names\n",
    "sse_base.columns = ['N_Clusters', 'Madelon_SSE', 'Cars_SSE']\n",
    "cleaned_sse = (sse_base.assign(Clustering_Algorithm = 'K_Means') \n",
    "               .melt(id_vars=['Clustering_Algorithm', 'N_Clusters'], value_name='Value')\n",
    "               .assign(Dataset= lambda X: X.variable.str.split('_').str.get(0))\n",
    "               .assign(Metric= lambda X: X.variable.str.split('_').str.get(1))\n",
    "               .drop(columns=['variable'])\n",
    ")\n",
    "cleaned_sse\n",
    "\n",
    "def clean_clustering_metrics(fpath):\n",
    "    metric_df = pd.read_csv(fpath)\n",
    "    metric = fpath.split('/')[1].split('.')[0]\n",
    "    # Correct Spelling mistake\n",
    "    if metric == 'logliklihood':\n",
    "        metric='log-likelihood'\n",
    "    metric_df.columns = ['N_Clusters', 'Madelon_'+metric, 'Cars_'+metric]\n",
    "    clean_metric_df = (metric_df\n",
    "                   .melt(id_vars=['N_Clusters'], value_name='Value')\n",
    "                   .assign(Dataset= lambda X: X.variable.str.split('_').str.get(0))\n",
    "                   .assign(Metric= lambda X: X.variable.str.split('_').str.get(1))\n",
    "                   .drop(columns=['variable'])\n",
    "    )\n",
    "    if clean_metric_df.Metric.unique()[0] == 'log-likelihood':\n",
    "        clean_metric_df['Clustering_Algorithm'] = 'EM'\n",
    "    elif clean_metric_df.Metric.unique()[0] == 'SSE':\n",
    "        clean_metric_df['Clustering_Algorithm'] = 'K_Means'\n",
    "    else:\n",
    "        clean_metric_df['Clustering_Algorithm'] = np.nan\n",
    "        \n",
    "    column_order = ['Clustering_Algorithm', 'N_Clusters', 'Dataset', 'Metric', 'Value',]\n",
    "\n",
    "    return clean_metric_df[column_order]\n",
    "def clean_clustering_validation_metrics(algorithm_file_dir_prefix):\n",
    "    sse_fpath = f'{algorithm_file_dir_prefix}/SSE.csv'\n",
    "    em_fpath = f'{algorithm_file_dir_prefix}/logliklihood.csv'\n",
    "    \n",
    "    clean_sse = clean_clustering_metrics(sse_fpath)\n",
    "    clean_em = clean_clustering_metrics(em_fpath)\n",
    "    \n",
    "    clean_clustering_metics_df = (pd.concat([clean_sse, clean_em],\n",
    "                                         sort=False)\n",
    "                               .reset_index(drop=True)\n",
    "                              )\n",
    "    return clean_clustering_metics_df\n",
    "    \n",
    "\n",
    "test_fpath1 = f'{alg}/SSE.csv'\n",
    "test_fpath2 = f'{alg}/logliklihood.csv'\n",
    "\n",
    "# display(clean_clustering_metrics(test_fpath1))\n",
    "# display(clean_clustering_metrics(test_fpath2))\n",
    "clean_clustering_validation_metrics('ICA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Cleaning the classification/quality metrics of the clusters (accuracy when using cluster labels as predictions and Mutual information between cluster labels and target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc_df = pd.read_csv('BASE/cars acc.csv')\n",
    "(test_acc_df.rename(columns={'Unnamed: 0':'Clustering_Algorithm'})\n",
    " .melt(id_vars='Clustering_Algorithm', var_name='N_Clusters', value_name='Value',)\n",
    " .assign\n",
    "\n",
    ")\n",
    "\n",
    "def clean_clustering_classification_metric_df(fpath):\n",
    "    metric_df = pd.read_csv(fpath)\n",
    "    metric = fpath.split('/')[1].split('.')[0].split(' ')[1]\n",
    "    # Correct Spelling mistake\n",
    "    clean_metric_df = (metric_df.rename(columns={'Unnamed: 0':'Clustering_Algorithm'})\n",
    "     .melt(id_vars='Clustering_Algorithm', var_name='N_Clusters', value_name='Value',)\n",
    "    )\n",
    "    if metric == 'acc':\n",
    "        clean_metric_df['Metric'] = 'Accuracy'\n",
    "    elif metric == 'adjMI':\n",
    "        clean_metric_df['Metric'] = 'Mutual_Information'\n",
    "    else:\n",
    "        clean_metric_df['Metric'] = np.nan\n",
    "    \n",
    "    return clean_metric_df\n",
    "\n",
    "def clean_clustering_classification_metrics(algorithm_file_dir_prefix, collection_of_dataset_names):\n",
    "    clean_metric_dfs = []\n",
    "    for dataset in collection_of_dataset_names:\n",
    "        acc_fpath = f'{algorithm_file_dir_prefix}/{dataset} acc.csv'\n",
    "        adjmi_fpath = f'{algorithm_file_dir_prefix}/{dataset} adjMI.csv'\n",
    "#         print(acc_fpath)\n",
    "#         print(adjmi_fpath)\n",
    "        clean_acc = clean_clustering_classification_metric_df(acc_fpath)\n",
    "        clean_acc['Dataset'] = dataset\n",
    "        clean_adjmi = clean_clustering_classification_metric_df(adjmi_fpath)\n",
    "        clean_adjmi['Dataset'] = dataset\n",
    "\n",
    "\n",
    "        clean_classification_metric_df = (pd.concat([clean_acc, clean_adjmi],\n",
    "                                             sort=False)\n",
    "                                   .reset_index(drop=True)\n",
    "                                  )\n",
    "        clean_metric_dfs.append(clean_classification_metric_df)\n",
    "    \n",
    "    # Concat all together\n",
    "    clean_metric_df = (pd.concat(clean_metric_dfs,\n",
    "                                             sort=False)\n",
    "                                   .reset_index(drop=True)\n",
    "                                  )\n",
    "    column_order = ['Clustering_Algorithm', 'N_Clusters', 'Dataset', 'Metric', 'Value',]\n",
    "\n",
    "\n",
    "    return clean_metric_df[column_order]\n",
    "\n",
    "def clean_all_clustering_non_grid_search_metrics(algorithm_file_dir_prefix, collection_of_dataset_names):\n",
    "    \"\"\"Clean the clustering metrics (Accuracy, Mutual Info, SSE for Kmeans and Likelihood for EM\n",
    "    and pull into a single clean dataframe\"\"\"\n",
    "    clean_clustering_validation_metrics_df = clean_clustering_validation_metrics(algorithm_file_dir_prefix)\n",
    "    clean_clustering_classification_metrics_df = clean_clustering_classification_metrics(algorithm_file_dir_prefix, \n",
    "                                                                                         collection_of_dataset_names)\n",
    "    clean_metric_df = (pd.concat([clean_clustering_validation_metrics_df, clean_clustering_classification_metrics_df],\n",
    "                                             sort=False)\n",
    "                                   .reset_index(drop=True)\n",
    "                                  )\n",
    "    clean_metric_df['Data_Perspective'] = algorithm_file_dir_prefix\n",
    "    return clean_metric_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting one such pairing of clustering metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clustering_Algorithm</th>\n",
       "      <th>N_Clusters</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "      <th>Data_Perspective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>2</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>901709.421231</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>5</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>891880.862735</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>10</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>885554.749546</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>15</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>881723.610571</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K_Means</td>\n",
       "      <td>20</td>\n",
       "      <td>Madelon</td>\n",
       "      <td>SSE</td>\n",
       "      <td>878695.336027</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Clustering_Algorithm N_Clusters  Dataset Metric          Value  \\\n",
       "0              K_Means          2  Madelon    SSE  901709.421231   \n",
       "1              K_Means          5  Madelon    SSE  891880.862735   \n",
       "2              K_Means         10  Madelon    SSE  885554.749546   \n",
       "3              K_Means         15  Madelon    SSE  881723.610571   \n",
       "4              K_Means         20  Madelon    SSE  878695.336027   \n",
       "\n",
       "  Data_Perspective  \n",
       "0             BASE  \n",
       "1             BASE  \n",
       "2             BASE  \n",
       "3             BASE  \n",
       "4             BASE  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_all_clustering_non_grid_search_metrics('BASE', ['Cars', 'Madelon']).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 236 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_algorithm_clustering_methods = pd.concat([clean_all_clustering_non_grid_search_metrics(algorithm, ['Cars', 'Madelon'])\n",
    "                                    for algorithm in ['BASE', 'ICA', 'PCA', 'RP', 'RF']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to results HDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afurrier\\AppData\\Local\\Continuum\\miniconda3\\envs\\task\\lib\\site-packages\\pandas\\core\\generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed-integer,key->block1_values] [items->['Clustering_Algorithm', 'N_Clusters', 'Dataset', 'Metric', 'Data_Perspective']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "all_algorithm_clustering_methods.to_hdf('results/results.hdf', key='clustering', complib='blosc',complevel=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying to all algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These should be equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RP      108\n",
       "RF      108\n",
       "ICA     108\n",
       "BASE    108\n",
       "PCA     108\n",
       "Name: Data_Perspective, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_algorithm_clustering_methods.Data_Perspective.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Madelon    270\n",
       "Cars       270\n",
       "Name: Dataset, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_algorithm_clustering_methods.Dataset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile T-SNE Results to one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-19.816355</td>\n",
       "      <td>-39.049294</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19.696314</td>\n",
       "      <td>-3.217640</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-16.734158</td>\n",
       "      <td>-17.890333</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.546829</td>\n",
       "      <td>-13.654442</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-50.886955</td>\n",
       "      <td>-6.579526</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y  target\n",
       "0 -19.816355 -39.049294     1.0\n",
       "1  19.696314  -3.217640    -1.0\n",
       "2 -16.734158 -17.890333    -1.0\n",
       "3   5.546829 -13.654442    -1.0\n",
       "4 -50.886955  -6.579526    -1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_alg = 'BASE'\n",
    "test_data = 'madelon'\n",
    "tsne_test = pd.read_csv(f'{test_alg}/{test_data}2D.csv').drop(columns=['Unnamed: 0'])\n",
    "tsne_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset  Data_Perspective\n",
       "cars     BASE                1728\n",
       "         ICA                 1728\n",
       "         PCA                 1728\n",
       "         RF                  1728\n",
       "         RP                  1728\n",
       "madelon  BASE                1820\n",
       "         ICA                 1820\n",
       "         PCA                 1820\n",
       "         RF                  1820\n",
       "         RP                  1820\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pull_tsne(algorithm, dataset):\n",
    "    tsne = pd.read_csv(f'{algorithm}/{dataset}2D.csv').drop(columns=['Unnamed: 0'])\n",
    "    tsne['Dataset'] = dataset\n",
    "    tsne['Data_Perspective'] = algorithm\n",
    "    return tsne\n",
    "\n",
    "tsne_dfs = [pull_tsne(algorithm, 'cars')\n",
    " for algorithm \n",
    " in ['BASE', 'ICA', 'PCA', 'RP', 'RF']]+ [pull_tsne(algorithm, 'madelon')\n",
    " for algorithm \n",
    " in ['BASE', 'ICA', 'PCA', 'RP', 'RF']]\n",
    "\n",
    "\n",
    "\n",
    "pd.concat(tsne_dfs).groupby(by=['Dataset', 'Data_Perspective']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Target</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Data_Perspective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-31.615511</td>\n",
       "      <td>-25.296206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cars</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.212791</td>\n",
       "      <td>-12.543370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cars</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-27.641699</td>\n",
       "      <td>-27.702856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cars</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-19.924063</td>\n",
       "      <td>-29.720591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cars</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-17.961168</td>\n",
       "      <td>-15.166670</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cars</td>\n",
       "      <td>BASE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           X          Y  Target Dataset Data_Perspective\n",
       "0 -31.615511 -25.296206     0.0    cars             BASE\n",
       "1 -17.212791 -12.543370     0.0    cars             BASE\n",
       "2 -27.641699 -27.702856     0.0    cars             BASE\n",
       "3 -19.924063 -29.720591     0.0    cars             BASE\n",
       "4 -17.961168 -15.166670     0.0    cars             BASE"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsne_df = pd.concat(tsne_dfs).rename(columns={'x':'X', 'y':'Y', 'target':'Target'})\n",
    "tsne_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_df.to_hdf('results/results.hdf', key='tsne', complib='blosc',complevel=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile GridSearch Results to one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data_Perspective  Dataset  Clustering_Algorithm  Clustered_Data\n",
       "BASE              Cars     GMM                   1                 180\n",
       "                           Kmeans                1                 180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pull_grid_search(algorithm, dataset, clustering=True):\n",
    "    \"\"\"Given a data unsupervised learning algorithm, dataset name and whether it's \n",
    "    cluster related or not, pull grid search results\"\"\"\n",
    "    # Load the clustering data if necesary\n",
    "    if clustering:\n",
    "        # Load in Grid Searches from Clustering efforts\n",
    "        cluster_alg = 'GMM'\n",
    "        cluster1_df = pd.read_csv(f'{algorithm}/{dataset} cluster {cluster_alg}.csv').drop(columns=['Unnamed: 0'])\n",
    "        cluster1_df['Data_Perspective'] = algorithm        \n",
    "        cluster1_df['Dataset'] = dataset\n",
    "        cluster1_df['Clustering_Algorithm'] = cluster_alg\n",
    "        cluster1_df['Clustered_Data'] = 1\n",
    "        # Rename N components so that the concatenation works with columns aligned\n",
    "        n_components_colname = cluster1_df.filter(regex='(_n_|filt)').columns.values.tolist()[0]\n",
    "        cluster1_df.rename(columns={n_components_colname:'N_Components/Clusters/Features'}, inplace=True)\n",
    "        # Remove Individual Split columns\n",
    "        split_columns = cluster1_df.filter(regex='split').columns.values.tolist()\n",
    "        cluster1_df = cluster1_df.drop(columns=split_columns)\n",
    "\n",
    "        cluster_alg = 'Kmeans'\n",
    "        cluster2_df = pd.read_csv(f'{algorithm}/{dataset} cluster {cluster_alg}.csv').drop(columns=['Unnamed: 0'])\n",
    "        cluster2_df['Data_Perspective'] = algorithm        \n",
    "        cluster2_df['Dataset'] = dataset        \n",
    "        cluster2_df['Clustering_Algorithm'] = cluster_alg\n",
    "        cluster2_df['Clustered_Data'] = 1    \n",
    "        n_components_colname = cluster2_df.filter(regex='(_n_|filt)').columns.values.tolist()[0]\n",
    "        cluster2_df.rename(columns={n_components_colname:'N_Components/Clusters/Features'}, inplace=True)\n",
    "        # Remove Individual Split columns\n",
    "        split_columns = cluster2_df.filter(regex='split').columns.values.tolist()\n",
    "        cluster2_df = cluster2_df.drop(columns=split_columns)\n",
    "        \n",
    "        \n",
    "    # There's no dimension reduction for BASE data\n",
    "    if algorithm != 'BASE':\n",
    "        grid_search_df = pd.read_csv(f'{algorithm}/{dataset} dim red.csv').drop(columns=['Unnamed: 0'])\n",
    "        grid_search_df['Data_Perspective'] = algorithm        \n",
    "        grid_search_df['Dataset'] = dataset\n",
    "        grid_search_df['Clustering_Algorithm'] = 'None'\n",
    "        grid_search_df['Clustered_Data'] = 0 \n",
    "        n_components_colname = grid_search_df.filter(regex='(_n_|filt)').columns.values.tolist()[0]\n",
    "        grid_search_df.rename(columns={n_components_colname:'N_Components/Clusters/Features'}, inplace=True) \n",
    "        # Remove Individual Split columns\n",
    "        split_columns = grid_search_df.filter(regex='split').columns.values.tolist()\n",
    "        grid_search_df = grid_search_df.drop(columns=split_columns)        \n",
    "    \n",
    "  \n",
    "    if clustering & (algorithm != 'BASE'):         \n",
    "        clean_grid_search =  pd.concat([cluster1_df, cluster2_df, grid_search_df])\n",
    "        return clean_grid_search\n",
    "    elif clustering & (algorithm == 'BASE'):\n",
    "        clean_grid_search =  pd.concat([cluster1_df, cluster2_df])\n",
    "        return clean_grid_search\n",
    "    else:\n",
    "        return 'Either clustering or grid search not found'\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "pull_grid_search('BASE', 'Cars').groupby(by=['Data_Perspective',\n",
    " 'Dataset',\n",
    " 'Clustering_Algorithm',\n",
    " 'Clustered_Data']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 17)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pull_grid_search('BASE', 'Cars').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(560, 17)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pull_grid_search('ICA', 'Cars').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data_Perspective  Dataset  Clustering_Algorithm  Clustered_Data\n",
       "ICA               Cars     GMM                   1                 180\n",
       "                           Kmeans                1                 180\n",
       "                           None                  0                 200\n",
       "dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pull_grid_search('ICA', 'Cars').groupby(by=['Data_Perspective',\n",
    " 'Dataset',\n",
    " 'Clustering_Algorithm',\n",
    " 'Clustered_Data']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset  Data_Perspective\n",
       "Cars     BASE                360\n",
       "         ICA                 560\n",
       "         PCA                 540\n",
       "         RF                  560\n",
       "         RP                  560\n",
       "Madelon  BASE                360\n",
       "         ICA                 620\n",
       "         PCA                 620\n",
       "         RF                  620\n",
       "         RP                  620\n",
       "dtype: int64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_dfs = [pull_grid_search(algorithm, 'Cars')\n",
    " for algorithm \n",
    " in ['BASE', 'ICA', 'PCA', 'RP', 'RF']] + [pull_grid_search(algorithm, 'Madelon')\n",
    " for algorithm \n",
    " in ['BASE', 'ICA', 'PCA', 'RP', 'RF']]\n",
    "\n",
    "\n",
    "\n",
    "pd.concat(grid_search_dfs).groupby(by=['Dataset', 'Data_Perspective']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export grid search columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_NN__alpha</th>\n",
       "      <th>param_NN__hidden_layer_sizes</th>\n",
       "      <th>N_Components/Clusters/Features</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>Data_Perspective</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Clustering_Algorithm</th>\n",
       "      <th>Clustered_Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.084124</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>8.064048e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>2</td>\n",
       "      <td>{'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...</td>\n",
       "      <td>0.700231</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700232</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>BASE</td>\n",
       "      <td>Cars</td>\n",
       "      <td>GMM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.104676</td>\n",
       "      <td>0.010379</td>\n",
       "      <td>0.001203</td>\n",
       "      <td>2.456904e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>5</td>\n",
       "      <td>{'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...</td>\n",
       "      <td>0.700231</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>1</td>\n",
       "      <td>0.682722</td>\n",
       "      <td>0.033508</td>\n",
       "      <td>BASE</td>\n",
       "      <td>Cars</td>\n",
       "      <td>GMM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.152606</td>\n",
       "      <td>0.038785</td>\n",
       "      <td>0.001604</td>\n",
       "      <td>4.908651e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>10</td>\n",
       "      <td>{'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...</td>\n",
       "      <td>0.700231</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>1</td>\n",
       "      <td>0.700232</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>BASE</td>\n",
       "      <td>Cars</td>\n",
       "      <td>GMM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216791</td>\n",
       "      <td>0.041077</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>5.207766e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>15</td>\n",
       "      <td>{'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...</td>\n",
       "      <td>0.575231</td>\n",
       "      <td>0.249102</td>\n",
       "      <td>164</td>\n",
       "      <td>0.704856</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>BASE</td>\n",
       "      <td>Cars</td>\n",
       "      <td>GMM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.238133</td>\n",
       "      <td>0.028133</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>4.008064e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>20</td>\n",
       "      <td>{'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...</td>\n",
       "      <td>0.633681</td>\n",
       "      <td>0.133420</td>\n",
       "      <td>145</td>\n",
       "      <td>0.709349</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>BASE</td>\n",
       "      <td>Cars</td>\n",
       "      <td>GMM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.084124      0.010926         0.001003    8.064048e-07   \n",
       "1       0.104676      0.010379         0.001203    2.456904e-04   \n",
       "2       0.152606      0.038785         0.001604    4.908651e-04   \n",
       "3       0.216791      0.041077         0.002212    5.207766e-04   \n",
       "4       0.238133      0.028133         0.002708    4.008064e-04   \n",
       "\n",
       "   param_NN__alpha param_NN__hidden_layer_sizes  \\\n",
       "0              0.1                     (50, 50)   \n",
       "1              0.1                     (50, 50)   \n",
       "2              0.1                     (50, 50)   \n",
       "3              0.1                     (50, 50)   \n",
       "4              0.1                     (50, 50)   \n",
       "\n",
       "   N_Components/Clusters/Features  \\\n",
       "0                               2   \n",
       "1                               5   \n",
       "2                              10   \n",
       "3                              15   \n",
       "4                              20   \n",
       "\n",
       "                                              params  mean_test_score  \\\n",
       "0  {'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...         0.700231   \n",
       "1  {'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...         0.700231   \n",
       "2  {'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...         0.700231   \n",
       "3  {'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...         0.575231   \n",
       "4  {'NN__alpha': 0.1, 'NN__hidden_layer_sizes': (...         0.633681   \n",
       "\n",
       "   std_test_score  rank_test_score  mean_train_score  std_train_score  \\\n",
       "0        0.001624                1          0.700232         0.000405   \n",
       "1        0.001624                1          0.682722         0.033508   \n",
       "2        0.001624                1          0.700232         0.000405   \n",
       "3        0.249102              164          0.704856         0.008844   \n",
       "4        0.133420              145          0.709349         0.018340   \n",
       "\n",
       "  Data_Perspective Dataset Clustering_Algorithm  Clustered_Data  \n",
       "0             BASE    Cars                  GMM               1  \n",
       "1             BASE    Cars                  GMM               1  \n",
       "2             BASE    Cars                  GMM               1  \n",
       "3             BASE    Cars                  GMM               1  \n",
       "4             BASE    Cars                  GMM               1  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_grid_search_df = pd.concat(grid_search_dfs)\n",
    "clean_grid_search_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_grid_search_df.to_hdf('results/results.hdf', key='grid_search', complib='blosc',complevel=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "task",
   "language": "python",
   "name": "task"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
